---
- name: enable BBR and update packages
  hosts: servers
  remote_user: root
  gather_facts: no
  tasks:
    - name: set net.core.default_qdisc
      sysctl:
        name: net.core.default_qdisc
        value: fq
        state: present

    - name: set net.ipv4.tcp_congestion_control
      sysctl:
        name: net.ipv4.tcp_congestion_control
        value: bbr
        state: present
        reload: yes

    - name: update packages
      apt:
        update_cache: yes
        upgrade: yes

    - name: check if a reboot is required
      stat:
        path: /var/run/reboot-required
      register: reboot_required_file

    - name: reboot if required
      reboot:
      when: reboot_required_file.stat.exists == true
      ignore_errors: yes


- name: install softwares
  hosts: servers
  remote_user: root
  # gather_facts: no
  tasks:
    - name: install softwares
      apt:
        name:
          - wget
          - curl
          - debian-keyring
          - debian-archive-keyring
          - apt-transport-https
          - git
          - mercurial
          - binutils
          - bison
          - unzip
          - locate
          - htop
          - rsync
          - rclone
          - lrzsz
          - fail2ban
          - nftables
          - nano
          - build-essential
          - cmake
          - gdb
          - tmux
          #- net-tools
          - iproute2
          - lsof
          - vim
#          - iptables-persistent
          - bsdmainutils
        state: latest

    - name: Ensure nftables is enabled and started
      systemd:
        name: nftables
        enabled: yes
        state: started

    - name: Check if Caddy GPG key is already present
      stat:
        path: /usr/share/keyrings/caddy-stable-archive-keyring.gpg
      register: caddy_gpg_key

    - name: Update GPG key for Caddy v2
      shell: curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg
      when: not caddy_gpg_key.stat.exists

    - name: update apt source for caddy v2
      shell: curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | tee /etc/apt/sources.list.d/caddy-stable.list

    - name: install caddy v2 with apt
      apt:
        name: caddy
        state: latest
        update_cache: yes


- name: Disable and Remove Firewall
  hosts: servers
  become: yes
  vars:
    packages_to_remove: ["ufw", "iptables","iptables-persistent"]

  tasks:
    - name: Check if UFW is installed
      command: which ufw
      register: ufw_installed
      ignore_errors: true

    - name: Disable and stop UFW
      command: ufw disable
      when: ufw_installed.rc == 0

    - name: Stop UFW service
      systemd:
        name: ufw
        state: stopped
        enabled: no
      when: ufw_installed.rc == 0

    - name: Check if iptables is installed
      command: which iptables
      register: iptables_installed
      ignore_errors: true
      changed_when: false

    - name: Flush iptables rules
      iptables:
        flush: yes
      when: iptables_installed.rc == 0 and ansible_os_family == "Debian"

    - name: Save iptables rules
      ansible.builtin.command:
        cmd: netfilter-persistent save
      when: iptables_installed.rc == 0 and ansible_os_family == "Debian"

    - name: Uninstall UFW and iptables packages
      apt:
        name: "{{ packages_to_remove }}"
        state: absent
        purge: yes
      when: ufw_installed.rc == 0 or iptables_installed.rc == 0


- name: Install Docker
  hosts: servers
  gather_facts: yes
  become: yes
  vars:
    arch_mapping:
      x86_64: amd64
      aarch64: arm64
  tasks:
#    - name: Check if Docker is already installed
#      command: docker --version
#      register: docker_installed
#      failed_when: false
#      changed_when: false
    - name: Check if Docker daemon is already installed
      command: which dockerd
      register: docker_daemon_installed
      failed_when: false
      changed_when: false

    - name: Set proceed_with_reinstallation fact
      set_fact:
        proceed_with_reinstallation: "{{ force_reinstalls | default('false') | bool or docker_daemon_installed.rc != 0 }}"

    - block:
        - name: Uninstall unofficial packages
          apt:
            name: "{{ item }}"
            state: absent
          loop:
            - docker.io
            - docker-doc
            - docker-compose
            - docker-compose-v2
            - podman-docker
            - containerd
            - runc

        - name: Update apt cache and install necessary packages
          apt:
            update_cache: yes
            name:
              - ca-certificates
              - curl
              - gnupg
            state: present

        - name: Ensure /etc/apt/keyrings directory exists
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: "0755"

        - name: Add Docker's official GPG key
          apt_key:
            url: https://download.docker.com/linux/{{ ansible_distribution|lower }}/gpg
            state: present
            keyring: /etc/apt/keyrings/docker.gpg

        - name: Print architecture variables
          debug:
            msg: "Architecture: {{ ansible_architecture }}, Codename: {{ ansible_lsb.codename }}"

        - name: Check if Docker repository exists
          ansible.builtin.stat:
            path: /etc/apt/sources.list.d/docker.list
          register: docker_repo_file

        - name: Add Docker repository
          ansible.builtin.apt_repository:
            repo: "deb [arch={{ arch_mapping[ansible_architecture] | default(ansible_architecture) }} signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/{{ ansible_distribution|lower }} {{ ansible_lsb.codename }} stable"
            filename: docker
            state: present
          when: not docker_repo_file.stat.exists

        - name: Update apt cache after adding Docker repository
          apt:
            update_cache: yes
          when: not docker_repo_file.stat.exists

        - name: Install Docker CE and related packages
          apt:
            name:
              - docker-ce
              - docker-ce-cli
              - containerd.io
              - docker-buildx-plugin
              - docker-compose-plugin
            state: latest
            update_cache: yes

        - name: Add Docker group
          group:
            name: docker
            state: present

        - name: Add user to Docker group
          user:
            name: "{{ ansible_user }}"
            groups: docker
            append: true

        - name: Enable and start Docker services
          systemd:
            name: "{{ item }}"
            enabled: true
            state: started
          loop:
            - docker.service
            - containerd.service
      when: proceed_with_reinstallation


- name: Install Miniconda3 conditionally
  hosts: servers
  become: yes
  gather_facts: yes
  vars:
    miniconda_base_url: "https://repo.anaconda.com/miniconda"
    miniconda_installer: "Miniconda3-latest-Linux-{{ ansible_architecture }}.sh"
  tasks:
    - name: Check if Miniconda3 is installed
      command: test -d /opt/miniconda3
      register: miniconda_installed
      failed_when: false
      changed_when: false

    - name: Set proceed_with_reinstallation fact for Miniconda3
      set_fact:
        proceed_with_reinstallation_miniconda: "{{ force_reinstalls | default('false') | bool or miniconda_installed.rc != 0 }}"

    - block:
        - name: Download Miniconda3 installer for the respective architecture
          get_url:
            url: "{{ miniconda_base_url }}/{{ miniconda_installer }}"
            dest: "/tmp/{{ miniconda_installer }}"
            mode: 0755

        - name: Install Miniconda3
          shell: bash /tmp/{{ miniconda_installer }} -b -p /opt/miniconda3
          args:
            creates: /opt/miniconda3

        - name: Set miniconda3 path to bashrc
          lineinfile:
            path: ~/.bashrc
            line: 'export PATH="/opt/miniconda3/bin:$PATH"'
            create: yes

        - name: Configure Miniconda to not activate base environment on start
          shell: /opt/miniconda3/bin/conda config --set auto_activate_base false
      when: proceed_with_reinstallation_miniconda


# Repeat the pattern for fnm, GVM, and Rustup installation blocks
- name: Install fnm (Fast Node Manager) conditionally
  hosts: servers
  become: yes
  tasks:
    - name: Check if fnm is installed
      command: test -f /root/.local/share/fnm/fnm
      register: fnm_installed
      failed_when: false
      changed_when: false

    - name: Set proceed_with_reinstallation fact for fnm
      set_fact:
        proceed_with_reinstallation_fnm: "{{ force_reinstalls | default('false') | bool or fnm_installed.rc != 0 }}"

    - block:
        - name: Download and install fnm
          shell: |
            curl -fsSL https://github.com/Schniz/fnm/raw/master/.ci/install.sh | bash
          args:
            creates: /usr/local/bin/fnm

        - name: Add fnm init script to shell configuration
          lineinfile:
            path: "{{ ansible_env.HOME }}/.bashrc"
            line: 'eval "$(fnm env)"'
            create: yes
      when: proceed_with_reinstallation_fnm


- name: Install GVM (Go Version Manager) conditionally
  hosts: servers
  become: yes
  tasks:
    - name: Check if GVM is already installed
      shell: test -d /root/.gvm
      register: gvm_installed
      ignore_errors: true
      failed_when: false
      changed_when: false

    - name: Set proceed_with_reinstallation fact for GVM
      set_fact:
        proceed_with_reinstallation_gvm: "{{ force_reinstalls | default('false') | bool or gvm_installed.rc != 0 }}"

    - block:
        - name: Install Bison
          apt:
            name: bison
            state: present
          when: ansible_os_family == "Debian"

        - name: Remove existing GVM installation
          file:
            path: /root/.gvm
            state: absent

        - name: Install GVM
          shell: curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer | bash
      when: proceed_with_reinstallation_gvm


- name: Install Rustup (Rust Toolchain Installer) conditionally
  hosts: servers
  become: yes
  tasks:
    - name: Check if Rustup is installed
      command: test -f "{{ ansible_env.HOME }}/.cargo/bin/rustup"
      register: rustup_installed
      failed_when: false
      changed_when: false

    - name: Set proceed_with_reinstallation fact for Rustup
      set_fact:
        proceed_with_reinstallation_rustup: "{{ force_reinstalls | default('false') | bool or rustup_installed.rc != 0 }}"

    - block:
        - name: Install Rustup
          shell: |
            curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
          args:
            executable: /bin/bash
          environment:
            USER: "{{ ansible_user }}"
            HOME: "{{ ansible_env.HOME }}"
      when: proceed_with_reinstallation_rustup


- name: Configure nftables rules
  hosts: servers
  remote_user: root
  gather_facts: no
  become: yes
  vars:
    custom_block_ports: [14444, 14445] # 示例自定义端口列表

  tasks:
    - name: Allow local access to database and custom ports
      shell: |
        nft add rule inet filter input ip saddr 127.0.0.1 tcp dport {3306, 5432, 27017, 9092, {{ custom_block_ports | join(', ') }} } accept

    - name: Block external access to database and custom ports
      shell: |
        nft add rule inet filter input tcp dport {3306, 5432, 27017, 9092, {{ custom_block_ports | join(', ') }} } drop

    - name: Save nftables configuration
      shell: nft list ruleset > /etc/nftables.conf


- name: Configure .vimrc
  hosts: servers
  remote_user: root
  gather_facts: no
  become: yes
  tasks:
    - name: Rename /root/.vimrc to /root/.backup-vimrc
      command: mv /root/.vimrc /root/.backup-vimrc
      args:
        creates: /root/.backup-vimrc # 这个参数确保命令只在目标文件不存在时执行
      ignore_errors: true # 如果文件不存在，忽略错误
      changed_when: false # 除非实际进行了移动操作，否则不标记为 changed

    - name: Copy .vimrc.j2 to remote /root/.vimrc
      template:
        src: templates/.vimrc.j2
        dest: /root/.vimrc
        owner: root
        group: root
        mode: "0644"


- name: Configure and restart fail2ban
  hosts: servers
  remote_user: root
  gather_facts: no
  become: yes
  tasks:
    - name: Ensure the backup file is absent before moving
      file:
        path: /etc/fail2ban/jail.local.backup
        state: absent

    - name: Move /etc/fail2ban/jail.local to /etc/fail2ban/jail.local.backup
      command: mv /etc/fail2ban/jail.local /etc/fail2ban/jail.local.backup
      args:
        removes: /etc/fail2ban/jail.local

    - name: Copy jail.local.j2 to remote /etc/fail2ban/jail.local
      template:
        src: templates/jail.local.j2
        dest: /etc/fail2ban/jail.local
        owner: root
        group: root
        mode: "0644"

    - name: Restart and enable fail2ban service
      systemd:
        name: fail2ban
        state: restarted
        enabled: yes


- name: Final reboot
  hosts: servers
  remote_user: root
  gather_facts: no
  become: yes
  tasks:
    - name: final reboot
      reboot:
